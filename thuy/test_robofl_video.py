import cv2
import os
from roboflow import roboflow

rf = Roboflow(api_key="wxmpb1PyA5I08QLpxyH5")
project = rf.workspace("nguyen-utdt0").project("my-first-project-4rdca")
model = project.version(2).model  


input_video_path = "parkour2.mp4" # Video g·ªëc c·∫ßn x·ª≠ l√Ω
output_video_path = "datasets/results/result_parkour2.mp4" # Video k·∫øt qu·∫£ ƒë·∫ßy ƒë·ªß, c√≥ v·∫Ω bounding box.
output_danger_path = "datasets/results/result_danger_parkour2.mp4" # Video ch·ªâ ch·ª©a c√°c frame c√≥ h√†nh vi nguy hi·ªÉm

cap = cv2.VideoCapture(input_video_path) # M·ªü video ƒë·ªÉ ƒë·ªçc frame.
if not cap.isOpened(): # Ki·ªÉm tra video c√≥ m·ªü ƒë∆∞·ª£c kh√¥ng
    raise Exception(f"Kh√¥ng th·ªÉ m·ªü video: {input_video_path}")


# cap.get() tr·∫£ v·ªÅ gi√° tr·ªã ki·ªÉu float.
# Nh∆∞ng khi t·∫°o video m·ªõi v·ªõi VideoWriter, k√≠ch th∆∞·ªõc ph·∫£i l√† s·ªë nguy√™n (int)
width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
# OpenCV tr·∫£ v·ªÅ FPS m√† video g·ªëc ƒë∆∞·ª£c ghi.
# fps l√† s·ªë khung h√¨nh tr√™n gi√¢y (Frames Per Second) c·ªßa video
fps    = cap.get(cv2.CAP_PROP_FPS)
# fourcc l√† vi·∫øt t·∫Øt c·ªßa ‚ÄúFour Character Code‚Äù
# ƒê√¢y l√† Codec l√† ph·∫ßn m·ªÅm/thu·∫≠t to√°n n√©n d·ªØ li·ªáu video ƒë·ªÉ
# D·∫•u * trong Python unpack chu·ªói th√†nh 4 ƒë·ªëi s·ªë ri√™ng l·∫ª: 'm','p','4','v'.
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))
out_danger = cv2.VideoWriter(output_danger_path, fourcc, fps, (width, height))

print("üöÄ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω video... (nh·∫•n Q ƒë·ªÉ tho√°t)")

# ================= 3. Bi·∫øn ƒë·∫øm =================
danger_count = 0
frame_index = 0

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    frame_index += 1

    # confidence=0.5: ch·ªâ l·∫•y d·ª± ƒëo√°n ‚â• 50% tin c·∫≠y.
    # overlap=30: ki·ªÉm so√°t bounding box b·ªã tr√πng l·∫∑p.
    results = model.predict(frame, confidence=0.5, overlap=30).json()  
    predictions = results.get('predictions', [])

    danger_in_frame = False

    for pred in predictions:
        x1 = int(pred['x'] - pred['width']/2)
        y1 = int(pred['y'] - pred['height']/2)
        x2 = int(pred['x'] + pred['width']/2)
        y2 = int(pred['y'] + pred['height']/2)
        cls = pred['class']        # 'normal' ho·∫∑c 'suicide'
        conf = pred['confidence']

        # V·∫Ω bounding box
        if cls.lower() == 'suicide_attempt':
            color = (0,0,255)  # ƒë·ªè
            danger_in_frame = True
            print(f"[Frame {frame_index}] ‚ö†Ô∏è C·∫£nh b√°o: ph√°t hi·ªán h√†nh vi nguy hi·ªÉm v·ªõi confidence {conf:.2f}")
        else:
            color = (0,255,0)  # xanh

        cv2.rectangle(frame, (x1,y1), (x2,y2), color, 2)
        cv2.putText(frame, f"{cls} {conf:.2f}", (x1, y1-10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)

    # L∆∞u video ƒë·∫ßy ƒë·ªß
    out.write(frame)

    # N·∫øu frame c√≥ h√†nh vi nguy hi·ªÉm, l∆∞u v√†o video ri√™ng
    if danger_in_frame:
        out_danger.write(frame)
        danger_count += 1

    # Hi·ªÉn th·ªã realtime (t√πy ch·ªçn)
    cv2.imshow('Result', frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
out.release()
out_danger.release()
cv2.destroyAllWindows()

print(f"‚úÖ Video k·∫øt qu·∫£ ƒë√£ l∆∞u t·∫°i: {output_video_path}")
print(f"‚úÖ Video c√°c frame nguy hi·ªÉm ƒë√£ l∆∞u t·∫°i: {output_danger_path}")
print(f"‚ö†Ô∏è T·ªïng s·ªë frame nguy hi·ªÉm: {danger_count}")
